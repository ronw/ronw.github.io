<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
  "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
  <title>Ron Weiss</title>
  <link rel="stylesheet" type="text/css" href="style.css">
  <meta http-equiv="Content-Type"
  content="text/html; charset=iso-8859-1" />
</head>

<body>


<div class="navigation">
  <div class="menuitem">
    <a title="Home" href="index.html">Home</a>
  </div>
  <div class="menuitem">
    <a title="Projects" href="projects.html">Projects</a>
  </div>
  <div class="menuitem">
    <a title="Code" href="http://www.github.com/ronw">Code</a>
  </div>
  <div class="menuitem">
<!--
    <a title="Resume" href="ronweiss-resume.pdf">Resume</a>
    /
-->
    <a title="CV" href="ronweiss-cv.pdf">CV</a>
  </div>
<!--  
  <div class="menuitem">
    <a title="Photos" href="photos/index.html">Photos</a>
  </div>
  <div class="menuitem">
    <a title="Index" href="WikiIndex.html">Index</a>
  </div>
-->  

</div><!-- menu ends here -->

<div class="mainText">

<h1 id="top">
Ron Weiss
</h1>

<!-- Page published by Muse begins here -->

<p class="image"><img align="left" src="images/ron-ee6884-cropped.jpg" />
</p>

<p>I'm currently a software engineer at <a href="http://g.co/brain">Google Brain</a>.  While at <a href="http://research.google.com/pubs/RonWeiss.html">Google</a>
I've worked on noise robust speech recognition and music
recommendation, among other things.  Previously, I was a postdoc
working on music information retrieval with <a href="http://homepages.nyu.edu/~jb2843/">Juan Bello</a> at <a href="http://marl.smusic.nyu.edu">MARL</a> at <a href="http://www.nyu.edu">NYU</a>.
Earlier still, I was a graduate research assistant working with
<a href="http://www.ee.columbia.edu/~dpwe/">Dan Ellis</a> in the Laboratory for the Recognition and Organization of
Speech and Audio (<a href="http://labrosa.ee.columbia.edu/">LabROSA</a>).  I defended my <a href="pubs/ronw-thesis.pdf">dissertation</a> in May 2009
(watch me write it at about 50,000 * real-time <a href="http://www.youtube.com/watch?v=8FsO6m77vlE">here</a>).</p>

<p>My research interests lie at the intersection of audio signal
processing and machine learning.  My dissertation research was devoted
to <a href="index.html#pubs">model based source separation</a>, but I also found time to do a bit of
<a href="http://labrosa.ee.columbia.edu/meapsoft">music signal analysis</a> to create some <a href="http://www.meapsoft.com/showcase.php">wacky remixes</a> on the side.  I've
also done some work on music information retrieval.  You can find
more (outdated) information on my <a href="projects.html">projects</a> page.</p>

<p>You might also be interested in some of my freely available <a href="http://github.com/ronw/">code</a>,
including assorted Python <a href="http://github.com/ronw/frontend">audio</a> <a href="http://github.com/ronw/gm">processing</a> <a href="http://github.com/ronw/daap-player">modules</a>, and useful Matlab
tools for <a href="http://github.com/ronw/celltools">functional programming</a>, <a href="http://ronw.github.com/plottools/">easier plotting</a>, <a href="http://github.com/ronw/matlab_hmm">training GMMs/HMMs</a>,
and <a href="http://github.com/ronw/matlab_htk/">interfacing</a> with <a href="http://htk.eng.cam.ac.uk">HTK</a>.  I've also spent some time hacking on the
<a href="http://bitbucket.org/ronw/gordon">Gordon music database</a> and <a href="https://scikit-learn.org/">scikit-learn</a>.</p>









<h3>Invited Talks</h3>

<ul><a name="talks" id="talks"></a>
<li><strong>Generating speech from speech: How end-to-end is too far?</strong>, <a href="http://www.saneworkshop.org/sane2019/">Speech and Audio in the Northeast (SANE) Workshop</a>, October 2019.  [ <a href="talks/2019-10-24-sane-speech_to_speech.pdf">slides</a> ]</li>
<li><strong>Training neural network acoustic models on (multichannel) waveforms</strong>, <a href="http://saneworkshop.org/sane2015">Speech and Audio in the Northeast (SANE) Workshop</a>, October 2015.  [ <a href="talks/2015-10-22-sane-waveform_cldnn-slides.pdf">slides</a> <code>|</code> <a href="https://youtu.be/sI_8EA0_ha8">video</a> ]</li>
</ul>


<h3>Publications</h3>

<p><a name="pubs" id="pubs"></a>
<div class="cleantable">


<!-- This document was automatically generated with bibtex2html 1.99
     (see http://www.lri.fr/~filliatr/bibtex2html/),
     with the following command:
     bibtex2html -q -d -r -noabstract -nodoc -nofooter -s ronw_web -nf slides slides -nf poster poster -nf web web -nf http http -nf arxiv arxiv -nf reviews reviews pubs/ronwpubs.bib  -->


<table>

<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="sun2020prosody_prior">1</a>]
</td>
<td class="bibtexitem">
G.&nbsp;Sun, Y.&nbsp;Zhang, R.&nbsp;J. Weiss, Y.&nbsp;Cao, H.&nbsp;Zen, A.&nbsp;Rosenberg, B.&nbsp;Ramabhadran,
  and Y.&nbsp;Wu.
 <b>Generating diverse and natural text-to-speech samples using a
  quantized fine-grained VAE and auto-regressive prosody prior</b>.
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, May 2020.
[&nbsp;<a href="ronwpubs_bib.html#sun2020prosody_prior">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/2002.03788">arxiv</a>&nbsp;| 
<a href="https://google.github.io/tacotron/publications/prosody_prior">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="sun2020hierarchical_prosody">2</a>]
</td>
<td class="bibtexitem">
G.&nbsp;Sun, Y.&nbsp;Zhang, R.&nbsp;J. Weiss, Y.&nbsp;Cao, H.&nbsp;Zen, and Y.&nbsp;Wu.
 <b>Fully-hierarchical fine-grained prosody modeling for
  interpretable speech synthesis</b>.
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, May 2020.
[&nbsp;<a href="ronwpubs_bib.html#sun2020hierarchical_prosody">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/2002.03785">arxiv</a>&nbsp;| 
<a href="https://google.github.io/tacotron/publications/hierarchical_prosody">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="chorowski2019unsupervised">3</a>]
</td>
<td class="bibtexitem">
J.&nbsp;Chorowski, R.&nbsp;J. Weiss, S.&nbsp;Bengio, and A.&nbsp;van&nbsp;den Oord.
 <b>Unsupervised speech representation learning using WaveNet
  autoencoders</b>.
 <em>IEEE/ACM Transactions on Audio, Speech, and Language
  Processing</em>, 27(12):2041--2053, December 2019.
[&nbsp;<a href="ronwpubs_bib.html#chorowski2019unsupervised">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TASLP.2019.2938863">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1901.08810">arxiv</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="zhang2019learning">4</a>]
</td>
<td class="bibtexitem">
Y.&nbsp;Zhang, R.&nbsp;J. Weiss, H.&nbsp;Zen, Y.&nbsp;Wu, Z.&nbsp;Chen, R.&nbsp;J. Skerry-Ryan, Y.&nbsp;Jia,
  A.&nbsp;Rosenberg, and B.&nbsp;Ramabhadran.
 <b>Learning to Speak Fluently in a Foreign Language: Multilingual
  Speech Synthesis and Cross-Language Voice Cloning</b>.
 In <em>Proc. Interspeech</em>, Graz, Austria, September 2019.
[&nbsp;<a href="ronwpubs_bib.html#zhang2019learning">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2019-2668">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1907.04448">arxiv</a>&nbsp;| 
<a href="https://google.github.io/tacotron/publications/multilingual">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="zen2019libritts">5</a>]
</td>
<td class="bibtexitem">
H.&nbsp;Zen, V.&nbsp;Dang, R.&nbsp;Clark, Y.&nbsp;Zhang, R.&nbsp;J. Weiss, Y.&nbsp;Jia, Z.&nbsp;Chen, and Y.&nbsp;Wu.
 <b>LibriTTS: A Corpus Derived from LibriSpeech for Text-to-Speech</b>.
 In <em>Proc. Interspeech</em>, Graz, Austria, September 2019.
[&nbsp;<a href="ronwpubs_bib.html#zen2019libritts">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2019-2441">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1904.02882">arxiv</a>&nbsp;| 
<a href="http://www.openslr.org/60/">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="biadsy2019parrotron">6</a>]
</td>
<td class="bibtexitem">
F.&nbsp;Biadsy, R.&nbsp;J. Weiss, P.&nbsp;J. Moreno, D.&nbsp;Kanvesky, and Y.&nbsp;Jia.
 <b>Parrotron: An End-to-End Speech-to-Speech Conversion Model and
  its Applications to Hearing-Impaired Speech and Speech Separation</b>.
 In <em>Proc. Interspeech</em>, Graz, Austria, September 2019.
[&nbsp;<a href="ronwpubs_bib.html#biadsy2019parrotron">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2019-1789">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1904.04169">arxiv</a>&nbsp;| 
<a href="https://google.github.io/tacotron/publications/parrotron">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="jia2019direct">7</a>]
</td>
<td class="bibtexitem">
Y.&nbsp;Jia, R.&nbsp;J. Weiss, F.&nbsp;Biadsy, W.&nbsp;Macherey, M.&nbsp;Johnson, Z.&nbsp;Chen, and Y.&nbsp;Wu.
 <b>Direct Speech-to-Speech Translation with a Sequence-to-Sequence
  Model</b>.
 In <em>Proc. Interspeech</em>, Graz, Austria, September 2019.
[&nbsp;<a href="ronwpubs_bib.html#jia2019direct">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2019-1951">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1904.06037">arxiv</a>&nbsp;| 
<a href="https://google-research.github.io/lingvo-lab/translatotron">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="wang2019voicefilter">8</a>]
</td>
<td class="bibtexitem">
Q.&nbsp;Wang, H.&nbsp;Muckenhirn, K.&nbsp;Wilson, P.&nbsp;Sridhar, Z.&nbsp;Wu, J.&nbsp;Hershey, R.&nbsp;A.
  Saurous, R.&nbsp;J. Weiss, Y.&nbsp;Jia, and I.&nbsp;Lopez-Moreno.
 <b>VoiceFilter: Targeted Voice Separation by Speaker-Conditioned
  Spectrogram Masking</b>.
 In <em>Proc. Interspeech</em>, Graz, Austria, September 2019.
[&nbsp;<a href="ronwpubs_bib.html#wang2019voicefilter">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2019-1101">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1810.04826">arxiv</a>&nbsp;| 
<a href="https://google.github.io/speaker-id/publications/VoiceFilter">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="antognini2019audio">9</a>]
</td>
<td class="bibtexitem">
J.&nbsp;M. Antognini, M.&nbsp;Hoffman, and R.&nbsp;J. Weiss.
 <b>Audio Texture Synthesis with Random Neural Networks: Improving
  Diversity and Quality</b>.
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, Brighton, UK, May 2019.
[&nbsp;<a href="ronwpubs_bib.html#antognini2019audio">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2019.8682598">DOI</a>&nbsp;| 
<a href="https://antognini-google.github.io/audio_textures">web</a>&nbsp;| 
<a href="pubs/icassp2019-texture-poster.pdf">poster</a>&nbsp;| 
<a href="pubs/icassp2019-texture.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="guo2019spelling">10</a>]
</td>
<td class="bibtexitem">
J.&nbsp;Guo, T.&nbsp;N. Sainath, and R.&nbsp;J. Weiss.
 <b>A Spelling Correction Model for End-to-End Speech Recognition</b>.
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, Brighton, UK, May 2019.
[&nbsp;<a href="ronwpubs_bib.html#guo2019spelling">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2019.8683745">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1902.07178">arxiv</a>&nbsp;| 
<a href="pubs/icassp2019-spelling-slides.pdf">slides</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="jia2019leveraging">11</a>]
</td>
<td class="bibtexitem">
Y.&nbsp;Jia, M.&nbsp;Johnson, W.&nbsp;Macherey, R.&nbsp;J. Weiss, Y.&nbsp;Cao, C.&nbsp;C. Chiu, N.&nbsp;Ari,
  S.&nbsp;Laurenzo, and Y.&nbsp;Wu.
 <b>Leveraging Weakly Supervised Data to Improve End-to-End
  Speech-to-Text Translation</b>.
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, Brighton, UK, May 2019.
[&nbsp;<a href="ronwpubs_bib.html#jia2019leveraging">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2019.8683343">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1811.02050">arxiv</a>&nbsp;| 
<a href="pubs/icassp2019-speech_translation-slides.pdf">slides</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="hsu2019hierarchical">12</a>]
</td>
<td class="bibtexitem">
W.&nbsp;N. Hsu, Y.&nbsp;Zhang, R.&nbsp;J. Weiss, H.&nbsp;Zen, Y.&nbsp;Wu, Y.&nbsp;Wang, Y.&nbsp;Cao, Y.&nbsp;Jia,
  Z.&nbsp;Chen, J.&nbsp;Shen, P.&nbsp;Nguyen, and R.&nbsp;Pang.
 <b>Hierarchical Generative Modeling for Controllable Speech
  Synthesis</b>.
 In <em>Proc. International Conference on Learning Representations
  (ICLR)</em>, New Orleans, USA, May 2019.
[&nbsp;<a href="ronwpubs_bib.html#hsu2019hierarchical">bib</a>&nbsp;| 
<a href="https://openreview.net/forum?id=rygkk305YQ">reviews</a>&nbsp;| 
<a href="https://arxiv.org/abs/1810.07217">arxiv</a>&nbsp;| 
<a href="https://google.github.io/tacotron/publications/gmvae_controllable_tts">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="hsu2018disentangling">13</a>]
</td>
<td class="bibtexitem">
W.&nbsp;N. Hsu, Y.&nbsp;Zhang, R.&nbsp;J. Weiss, Y.&nbsp;A. Chung, Y.&nbsp;Wang, Y.&nbsp;Wu, and J.&nbsp;Glass.
 <b>Disentangling Correlated Speaker and Noise for Speech Synthesis
  via Data Augmentation and Adversarial Factorization</b>.
 In <em>NeurIPS 2018 Workshop on Interpretability and Robustness in
  Audio, Speech, and Language</em>, Montreal, Canada, December 2018.
 also at <a href="https://dx.doi.org/10.1109/ICASSP.2019.8683561">ICASSP
  2019</a>.
[&nbsp;<a href="ronwpubs_bib.html#hsu2018disentangling">bib</a>&nbsp;| 
<a href="https://openreview.net/forum?id=Bkg9ZeBB37">reviews</a>&nbsp;| 
<a href="https://google.github.io/tacotron/publications/adv_tts">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="jia2018multispeaker">14</a>]
</td>
<td class="bibtexitem">
Y.&nbsp;Jia, Y.&nbsp;Zhang, R.&nbsp;J. Weiss, Q.&nbsp;Wang, J.&nbsp;Shen, F.&nbsp;Ren, Z.&nbsp;Chen, P.&nbsp;Nguyen,
  R.&nbsp;Pang, I.&nbsp;Lopez-Moreno, and Y.&nbsp;Wu.
 <b>Transfer Learning from Speaker Verification to Multispeaker
  Text-To-Speech Synthesis</b>.
 In <em>Advances in Neural Information Processing Systems (NeurIPS)</em>,
  Montreal, Canada, December 2018.
[&nbsp;<a href="ronwpubs_bib.html#jia2018multispeaker">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1806.04558">arxiv</a>&nbsp;| 
<a href="https://google.github.io/tacotron/publications/speaker_adaptation">web</a>&nbsp;| 
<a href="https://google.github.io/tacotron/publications/speaker_adaptation/poster.pdf">poster</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="skerryryan2018prosody">15</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Skerry-Ryan, E.&nbsp;Battenberg, Y.&nbsp;Xiao, Y.&nbsp;Wang, D.&nbsp;Stanton, J.&nbsp;Shor, R.&nbsp;J.
  Weiss, R.&nbsp;Clark, and R.&nbsp;A. Saurous.
 <b>Towards End-to-End Prosody Transfer for Expressive Speech
  Synthesis with Tacotron</b>.
 In <em>Proc. International Conference on Machine Learning (ICML)</em>,
  Stockholm, Sweden, July 2018.
[&nbsp;<a href="ronwpubs_bib.html#skerryryan2018prosody">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1803.09047">arxiv</a>&nbsp;| 
<a href="https://research.googleblog.com/2018/03/expressive-speech-synthesis-with.html">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="antognini18textures">16</a>]
</td>
<td class="bibtexitem">
J.&nbsp;Antognini, M.&nbsp;Hoffman, and R.&nbsp;J. Weiss.
 <b>Synthesizing Diverse, High-Quality Audio Textures</b>.
 <em>arXiv preprint arXiv:1806.08002</em>, June 2018.
[&nbsp;<a href="ronwpubs_bib.html#antognini18textures">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1806.08002">arxiv</a>&nbsp;| 
<a href="https://antognini-google.github.io/audio_textures/">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="chiu2018sota">17</a>]
</td>
<td class="bibtexitem">
C.-C.Chiu, T.&nbsp;N. Sainath, Y.&nbsp;Wu, R.&nbsp;Prabhavalkar, P.&nbsp;Nguyen, Z.&nbsp;Chen,
  A.&nbsp;Kannan, R.&nbsp;J. Weiss, K.&nbsp;Rao, K.&nbsp;Gonina, N.&nbsp;Jaitly, B.&nbsp;Li, J.&nbsp;Chorowski,
  and M.&nbsp;Bacchiani.
 <b>State-of-the-art Speech Recognition With Sequence-to-Sequence
  Models</b>.
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, Calgary, Canada, April 2018.
[&nbsp;<a href="ronwpubs_bib.html#chiu2018sota">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1712.01769">arxiv</a>&nbsp;| 
<a href="https://research.googleblog.com/2017/12/improving-end-to-end-models-for-speech.html">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="toshniwal2018multilingual">18</a>]
</td>
<td class="bibtexitem">
S.&nbsp;Toshniwal, T.&nbsp;N. Sainath, R.&nbsp;J. Weiss, B.&nbsp;Li, P.&nbsp;Moreno, E.&nbsp;Weinstein, and
  K.&nbsp;Rao.
 <b>Multilingual Speech Recognition With A Single End-To-End Model</b>.
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, Calgary, Canada, April 2018.
[&nbsp;<a href="ronwpubs_bib.html#toshniwal2018multilingual">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1711.01694">arxiv</a>&nbsp;| 
<a href="https://research.googleblog.com/2017/12/improving-end-to-end-models-for-speech.html">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="chorowski2018styletransfer">19</a>]
</td>
<td class="bibtexitem">
J.&nbsp;Chorowski, R.&nbsp;J. Weiss, R.&nbsp;A. Saurous, and S.&nbsp;Bengio.
 <b>On Using Backpropagation for Speech Texture Generation and Voice
  Conversion</b>.
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, Calgary, Canada, April 2018.
[&nbsp;<a href="ronwpubs_bib.html#chorowski2018styletransfer">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1712.08363">arxiv</a>&nbsp;| 
<a href="https://google.github.io/speech_style_transfer/samples.html">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="shen2018tacotron2">20</a>]
</td>
<td class="bibtexitem">
J.&nbsp;Shen, R.&nbsp;Pang, R.&nbsp;J. Weiss, M.&nbsp;Schuster, N.&nbsp;Jaitly, Z.&nbsp;Yang, Z.&nbsp;Chen,
  Y.&nbsp;Zhang, Y.&nbsp;Wang, R.&nbsp;J. Skerry-Ryan, R.&nbsp;A. Saurous, Y.&nbsp;Agiomyrgiannakis, and
  Y.&nbsp;Wu.
 <b>Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram
  Predictions</b>.
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, Calgary, Canada, April 2018.
[&nbsp;<a href="ronwpubs_bib.html#shen2018tacotron2">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1712.05884">arxiv</a>&nbsp;| 
<a href="https://research.googleblog.com/2017/12/tacotron-2-generating-human-like-speech.html">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="bello18content">21</a>]
</td>
<td class="bibtexitem">
J.&nbsp;P. Bello, P.&nbsp;Grosche, M.&nbsp;M&uuml;ller, and R.&nbsp;Weiss.
 <b>Content-Based Methods for Knowledge Discovery in Music</b>.
 In <em>Springer Handbook of Systematic Musicology</em>, pages 823--840.
  Springer, March 2018.
[&nbsp;<a href="ronwpubs_bib.html#bello18content">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-662-55004-5_39">DOI</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="li2017acoustic">22</a>]
</td>
<td class="bibtexitem">
B.&nbsp;Li, T.&nbsp;N. Sainath, A.&nbsp;Narayanan, J.&nbsp;Caroselli, M.&nbsp;Bacchiani, A.&nbsp;Misra,
  I.&nbsp;Shafran, H.&nbsp;Sak, G.&nbsp;Pundak, K.&nbsp;Chin, K.&nbsp;C. Sim, R.&nbsp;J. Weiss, K.&nbsp;Wilson,
  E.&nbsp;Variani, C.&nbsp;Kim, O.&nbsp;Siohan, M.&nbsp;Weintraub, E.&nbsp;McDermott, R.&nbsp;Rose, and
  M.&nbsp;Shannon.
 <b>Acoustic Modeling for Google Home</b>.
 In <em>Proc. Interspeech</em>, Stockholm, Sweden, August 2017.
[&nbsp;<a href="ronwpubs_bib.html#li2017acoustic">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2017-234">DOI</a>&nbsp;| 
<a href="pubs/interspeech2017-googlehome.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss2017sequence">23</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss, J.&nbsp;Chorowski, N.&nbsp;Jaitly, Y.&nbsp;Wu, and Z.&nbsp;Chen.
 <b>Sequence-to-Sequence Models Can Directly Translate Foreign
  Speech</b>.
 In <em>Proc. Interspeech</em>, Stockholm, Sweden, August 2017.
[&nbsp;<a href="ronwpubs_bib.html#weiss2017sequence">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2017-503">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1703.08581">arxiv</a>&nbsp;| 
<a href="pubs/interspeech2017-speech_translation-slides.pdf">slides</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="wang2017tacotron">24</a>]
</td>
<td class="bibtexitem">
Y.&nbsp;Wang, R.&nbsp;J. Skerry-Ryan, D.&nbsp;Stanton, Y.&nbsp;Wu, R.&nbsp;J. Weiss, N.&nbsp;Jaitly, Z.&nbsp;Yang,
  Y.&nbsp;Xiao, Z.&nbsp;Chen, S.&nbsp;Bengio, Q.&nbsp;Le, Y.&nbsp;Agiomyrgiannakis, R.&nbsp;Clark, and R.&nbsp;A.
  Saurous.
 <b>Tacotron: Towards End-To-End Speech Synthesis</b>.
 In <em>Proc. Interspeech</em>, Stockholm, Sweden, August 2017.
[&nbsp;<a href="ronwpubs_bib.html#wang2017tacotron">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2017-1452">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1703.10135">arxiv</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="raffel2017online">25</a>]
</td>
<td class="bibtexitem">
C.&nbsp;Raffel, T.&nbsp;Luong, P.&nbsp;J. Liu, R.&nbsp;J. Weiss, and D.&nbsp;Eck.
 <b>Online and Linear-Time Attention by Enforcing Monotonic
  Alignments</b>.
 In <em>Proc. International Conference on Machine Learning (ICML)</em>,
  Sydney, Australia, August 2017.
[&nbsp;<a href="ronwpubs_bib.html#raffel2017online">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1704.00784">arxiv</a>&nbsp;| 
<a href="http://proceedings.mlr.press/v70/raffel17a.html">http</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="hershey17audiocnn">26</a>]
</td>
<td class="bibtexitem">
S.&nbsp;Hershey, S.&nbsp;Chaudhuri, D.&nbsp;P.&nbsp;W. Ellis, J.&nbsp;F. Gemmeke, A.&nbsp;Jansen, R.&nbsp;C.
  Moore, M.&nbsp;Plakal, D.&nbsp;Platt, R.&nbsp;A. Saurous, B.&nbsp;Seybold, M.&nbsp;Slaney, R.&nbsp;J.
  Weiss, and K.&nbsp;Wilson.
 <b>CNN Architectures for Large-Scale Audio Classification</b>.
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, New Orleans, USA, March 2017.
[&nbsp;<a href="ronwpubs_bib.html#hershey17audiocnn">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2017.7952132">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1609.09430">arxiv</a>&nbsp;| 
<a href="pubs/icassp2017-audiocnn.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="sainath17multichannel">27</a>]
</td>
<td class="bibtexitem">
T.&nbsp;N. Sainath, R.&nbsp;J. Weiss, K.&nbsp;W. Wilson, B.&nbsp;Li, A.&nbsp;Narayanan, E.&nbsp;Variani,
  M.&nbsp;Bacchiani, I.&nbsp;Shafran, A.&nbsp;Senior, K.&nbsp;W. Chin, A.&nbsp;Misra, and C.&nbsp;Kim.
 <b>Multichannel Signal Processing with Deep Neural Networks for
  Automatic Speech Recognition</b>.
 <em>IEEE/ACM Transactions on Audio, Speech, and Language
  Processing</em>, 25(5):965--979, February 2017.
[&nbsp;<a href="ronwpubs_bib.html#sainath17multichannel">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TASLP.2017.2672401">DOI</a>&nbsp;| 
<a href="pubs/taslp2017-multichannel.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="sainath17raw">28</a>]
</td>
<td class="bibtexitem">
T.&nbsp;N. Sainath, R.&nbsp;J. Weiss, K.&nbsp;W. Wilson, B.&nbsp;Li, A.&nbsp;Narayanan, E.&nbsp;Variani,
  M.&nbsp;Bacchiani, I.&nbsp;Shafran, A.&nbsp;Senior, K.&nbsp;W. Chin, A.&nbsp;Misra, and C.&nbsp;Kim.
 <b>Raw Multichannel Processing Using Deep Neural Networks</b>.
 In <em>New Era for Robust Speech Recognition: Exploiting Deep
  Learning</em>. Springer, 2017.
[&nbsp;<a href="ronwpubs_bib.html#sainath17raw">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-319-64680-0">DOI</a>&nbsp;| 
<a href="pubs/jsalt2017-raw.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="sainath16speedups">29</a>]
</td>
<td class="bibtexitem">
T.&nbsp;N. Sainath, A.&nbsp;Narayanan, R.&nbsp;J. Weiss, E.&nbsp;Variani, K.&nbsp;W. Wilson,
  M.&nbsp;Bacchiani, and I.&nbsp;Shafran.
 <b>Reducing the Computational Complexity of Multimicrophone
  Acoustic Models with Integrated Feature Extraction</b>.
 In <em>Proc. Interspeech</em>, San Francisco, USA, September 2016.
[&nbsp;<a href="ronwpubs_bib.html#sainath16speedups">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2016-92">DOI</a>&nbsp;| 
<a href="pubs/interspeech2016-waveform_cldnn_speedups.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="li16adaptive">30</a>]
</td>
<td class="bibtexitem">
B.&nbsp;Li, T.&nbsp;N. Sainath, R.&nbsp;J. Weiss, K.&nbsp;W. Wilson, and M.&nbsp;Bacchiani.
 <b>Neural Network Adaptive Beamforming for Robust Multichannel
  Speech Recognition</b>.
 In <em>Proc. Interspeech</em>, San Francisco, USA, September 2016.
[&nbsp;<a href="ronwpubs_bib.html#li16adaptive">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2016-173">DOI</a>&nbsp;| 
<a href="pubs/interspeech2016-waveform_cldnn_adaptive.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="sainath16factored">31</a>]
</td>
<td class="bibtexitem">
T.&nbsp;N. Sainath, R.&nbsp;J. Weiss, K.&nbsp;W. Wilson, A.&nbsp;Narayanan, and M.&nbsp;Bacchiani.
 <b>Factored Spatial and Spectral Multichannel Raw Waveform
  CLDNNs</b>.
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, Shanghai, China, March 2016.
[&nbsp;<a href="ronwpubs_bib.html#sainath16factored">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2017.7952132">DOI</a>&nbsp;| 
<a href="pubs/icassp2016-factored_cldnn.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="sainath15multichannel">32</a>]
</td>
<td class="bibtexitem">
T.&nbsp;N. Sainath, R.&nbsp;J. Weiss, K.&nbsp;W. Wilson, A.&nbsp;Narayanan, M.&nbsp;Bacchiani, and
  A.&nbsp;Senior.
 <b>Speaker Location and Microphone Spacing Invariant Acoustic
  Modeling from Raw Multichannel Waveforms</b>.
 In <em>Proc. IEEE Automatic Speech Recognition and Understanding
  Workshop (ASRU)</em>, Scottsdale, USA, December 2015.
[&nbsp;<a href="ronwpubs_bib.html#sainath15multichannel">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ASRU.2015.7404770">DOI</a>&nbsp;| 
<a href="pubs/asru2015-multichannel_cldnn.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="sainath15waveform_cldnn">33</a>]
</td>
<td class="bibtexitem">
T.&nbsp;N. Sainath, R.&nbsp;J. Weiss, A.&nbsp;Senior, K.&nbsp;W. Wilson, and O.&nbsp;Vinyals.
 <b>Learning the Speech Front-End with Raw Waveform CLDNNs</b>.
 In <em>Proc. Interspeech</em>, Dresden, Germany, September 2015.
[&nbsp;<a href="ronwpubs_bib.html#sainath15waveform_cldnn">bib</a>&nbsp;| 
<a href="pubs/interspeech2015-waveform_cldnn.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="hoshen15waveformam">34</a>]
</td>
<td class="bibtexitem">
Y.&nbsp;Hoshen, R.&nbsp;J. Weiss, and K.&nbsp;W. Wilson.
 <b>Speech Acoustic Modeling from Raw Multichannel Waveforms</b>.
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, Brisbane, Australia, April 2015.
[&nbsp;<a href="ronwpubs_bib.html#hoshen15waveformam">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2015.7178847">DOI</a>&nbsp;| 
<a href="pubs/icassp2015-waveformam.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weston14awe">35</a>]
</td>
<td class="bibtexitem">
J.&nbsp;Weston, R.&nbsp;Weiss, and H.&nbsp;Yee.
 <b>Affinity Weighted Embedding</b>.
 In <em>Proc. International Conference on Machine Learning (ICML)</em>,
  pages 1215--1223, Beijing, China, June 2014.
[&nbsp;<a href="ronwpubs_bib.html#weston14awe">bib</a>&nbsp;| 
<a href="http://jmlr.org/proceedings/papers/v32/weston14.html">http</a>&nbsp;| 
<a href="pubs/icml2014-awe.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weston13kaos">36</a>]
</td>
<td class="bibtexitem">
J.&nbsp;Weston, H.&nbsp;Yee, and R.&nbsp;J. Weiss.
 <b>Learning to Rank Recommendations with the k-order Statistic
  Loss</b>.
 In <em>Proc. ACM Conference on Recommender Systems (RecSys)</em>,
  pages 245--248, Hong Kong, October 2013.
[&nbsp;<a href="ronwpubs_bib.html#weston13kaos">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/2507157.2507210">DOI</a>&nbsp;| 
<a href="pubs/recsys2013-kaos.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weston13usermax">37</a>]
</td>
<td class="bibtexitem">
J.&nbsp;Weston, R.&nbsp;J. Weiss, and H.&nbsp;Yee.
 <b>Nonlinear Latent Factorization by Embedding Multiple User
  Interests</b>.
 In <em>Proc. ACM Conference on Recommender Systems (RecSys)</em>,
  pages 65--68, Hong Kong, October 2013.
[&nbsp;<a href="ronwpubs_bib.html#weston13usermax">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/2507157.2507209">DOI</a>&nbsp;| 
<a href="pubs/recsys2013-usermax.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weston13awe">38</a>]
</td>
<td class="bibtexitem">
J.&nbsp;Weston, R.&nbsp;Weiss, and H.&nbsp;Yee.
 <b>Affinity Weighted Embedding</b>.
 In <em>Proc. International Conference on Learning Representations
  (ICLR)</em>, Scottsdale, USA, May 2013.
[&nbsp;<a href="ronwpubs_bib.html#weston13awe">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1301.4171">arxiv</a>&nbsp;| 
<a href="http://openreview.net/document/8bc82d3f-df5e-4602-bc3d-2f6fa0196f5f">http</a>&nbsp;| 
<a href="pubs/iclr2013-awe.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weston12lcr">39</a>]
</td>
<td class="bibtexitem">
J.&nbsp;Weston, C.&nbsp;Wang, R.&nbsp;Weiss, and A.&nbsp;Berenzweig.
 <b>Latent Collaborative Retrieval</b>.
 In <em>Proc. International Conference on Machine Learning (ICML)</em>,
  Edinburgh, Scotland, June 2012.
[&nbsp;<a href="ronwpubs_bib.html#weston12lcr">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1206.4603">arxiv</a>&nbsp;| 
<a href="http://icml.cc/discuss/2012/12.html">http</a>&nbsp;| 
<a href="pubs/icml2012-lcr.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="pedregosa11scikit-learn">40</a>]
</td>
<td class="bibtexitem">
F.&nbsp;Pedregosa, G.&nbsp;Varoquaux, A.&nbsp;Gramfort, V.&nbsp;Michel, B.&nbsp;Thirion, O.&nbsp;Grisel,
  M.&nbsp;Blondel, P.&nbsp;Prettenhofer, R.&nbsp;Weiss, V.&nbsp;Dubourg, J.&nbsp;Vanderplas, A.&nbsp;Passos,
  D.&nbsp;Cournapeau, M.&nbsp;Brucher, M.&nbsp;Perrot, and &Eacute;. Duchesnay.
 <b>scikit-learn: Machine Learning in Python</b>.
 <em>Journal of Machine Learning Research</em>, 12:2825--2830, October
  2011.
[&nbsp;<a href="ronwpubs_bib.html#pedregosa11scikit-learn">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1201.0490">arxiv</a>&nbsp;| 
<a href="http://jmlr.org/papers/v12/pedregosa11a.html">http</a>&nbsp;| 
<a href="pubs/jmlr2011-scikit-learn.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss11siplca">41</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss and J.&nbsp;P. Bello.
 <b>Unsupervised Discovery of Temporal Structure in Music</b>.
 <em>IEEE Journal of Selected Topics in Signal Processing</em>,
  5(6):1240--1251, October 2011.
[&nbsp;<a href="ronwpubs_bib.html#weiss11siplca">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/JSTSP.2011.2145356">DOI</a>&nbsp;| 
<a href="pubs/jstsp2011-siplca.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="bertin11evaluating">42</a>]
</td>
<td class="bibtexitem">
T.&nbsp;Bertin-Mahieux, G.&nbsp;Grindlay, R.&nbsp;J. Weiss, and D.&nbsp;P.&nbsp;W. Ellis.
 <b>Evaluating Music Sequence Models Through Missing Data</b>.
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, pages 177--180, Prague, Czech Republic,
  May 2011.
[&nbsp;<a href="ronwpubs_bib.html#bertin11evaluating">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2011.5946369">DOI</a>&nbsp;| 
<a href="pubs/icassp2011-imputation.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss11messlev">43</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss, M.&nbsp;I. Mandel, and D.&nbsp;P.&nbsp;W. Ellis.
 <b>Combining Localization Cues and Source Model Constraints for
  Binaural Source Separation</b>.
 <em>Speech Communication</em>, 53(5):606--621, May 2011.
 Special issue on Perceptual and Statistical Audition.
[&nbsp;<a href="ronwpubs_bib.html#weiss11messlev">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.specom.2011.01.003">DOI</a>&nbsp;| 
<a href="pubs/specom2011-messlev.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="bertin10patterns">44</a>]
</td>
<td class="bibtexitem">
T.&nbsp;Bertin-Mahieux, R.&nbsp;J. Weiss, and D.&nbsp;P.&nbsp;W. Ellis.
 <b>Clustering Beat-Chroma Patterns in a Large Music Database</b>.
 In <em>Proc. International Society for Music Information Retrieval
  Conference (ISMIR)</em>, pages 111--116, Utrecht, Netherlands, August 2010.
[&nbsp;<a href="ronwpubs_bib.html#bertin10patterns">bib</a>&nbsp;| 
<a href="http://www.columbia.edu/~tb2332/ProjClustering/ClusteringChromas.html">web</a>&nbsp;| 
<a href="pubs/ismir2010-beatchromapatterns.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss10nmfseg">45</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss and J.&nbsp;P. Bello.
 <b>Identifying Repeated Patterns in Music Using Sparse Convolutive
  Non-Negative Matrix Factorization</b>.
 In <em>Proc. International Society for Music Information Retrieval
  Conference (ISMIR)</em>, pages 123--128, Utrecht, Netherlands, August 2010.
 Best Paper Award.
[&nbsp;<a href="ronwpubs_bib.html#weiss10nmfseg">bib</a>&nbsp;| 
<a href="http://ronw.github.com/siplca-segmentation">web</a>&nbsp;| 
<a href="pubs/ismir2010-nmfseg-slides.pdf">slides</a>&nbsp;| 
<a href="pubs/ismir2010-nmfseg.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="cho10chordreco">46</a>]
</td>
<td class="bibtexitem">
T.&nbsp;Cho, R.&nbsp;J. Weiss, and J.&nbsp;P. Bello.
 <b>Exploring Common Variations in State of the Art Chord
  Recognition Systems</b>.
 In <em>Proc. Sound and Music Computing Conference (SMC)</em>, pages
  1--8, Barcelona, Spain, July 2010.
[&nbsp;<a href="ronwpubs_bib.html#cho10chordreco">bib</a>&nbsp;| 
<a href="pubs/smc2010-chordreco.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="mandel10messl">47</a>]
</td>
<td class="bibtexitem">
M.&nbsp;I. Mandel, R.&nbsp;J. Weiss, and D.&nbsp;P.&nbsp;W. Ellis.
 <b>Model-Based Expectation-Maximization Source Separation and
  Localization</b>.
 <em>IEEE Transactions on Audio, Speech, and Language Processing</em>,
  18(2):382--394, February 2010.
[&nbsp;<a href="ronwpubs_bib.html#mandel10messl">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TASL.2009.2029711">DOI</a>&nbsp;| 
<a href="http://github.com/mim/messl">web</a>&nbsp;| 
<a href="pubs/taslp09-messl.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss10ssc">48</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss and D.&nbsp;P.&nbsp;W. Ellis.
 <b>Speech Separation Using Speaker-Adapted Eigenvoice Speech
  Models</b>.
 <em>Computer Speech and Language</em>, 24(1):16--29, January 2010.
 Speech Separation and Recognition Challenge.
[&nbsp;<a href="ronwpubs_bib.html#weiss10ssc">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.csl.2008.03.003">DOI</a>&nbsp;| 
<a href="pubs/csl2008-eigenvoice_speech_sep.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss09vem">49</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss and D.&nbsp;P.&nbsp;W. Ellis.
 <b>A Variational EM Algorithm for Learning Eigenvoice Parameters
  in Mixed Signals</b>.
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, pages 113--116, Taipei, Taiwan, April
  2009.
[&nbsp;<a href="ronwpubs_bib.html#weiss09vem">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2009.4959533">DOI</a>&nbsp;| 
<a href="pubs/icassp2009-ev_vem-poster.pdf">poster</a>&nbsp;| 
<a href="pubs/icassp2009-ev_vem.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss09thesis">50</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss.
 <b>Underdetermined Source Separation Using Speaker Subspace
  Models</b>.
 PhD thesis, Department of Electrical Engineering, Columbia
  University, 2009.
[&nbsp;<a href="ronwpubs_bib.html#weiss09thesis">bib</a>&nbsp;| 
<a href="pubs/ronw-thesis-slides.pdf">slides</a>&nbsp;| 
<a href="pubs/ronw-thesis.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss08dysana">51</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss and T.&nbsp;Kristjansson.
 <b>DySANA: Dynamic Speech and Noise Adaptation for Voice
  Activity Detection</b>.
 In <em>Proc. Interspeech</em>, pages 127--130, Brisbane, Australia,
  September 2008.
[&nbsp;<a href="ronwpubs_bib.html#weiss08dysana">bib</a>&nbsp;| 
<a href="http://www.isca-speech.org/archive/interspeech_2008/i08_0127.html">http</a>&nbsp;| 
<a href="pubs/icslp2008-dysana-poster.pdf">poster</a>&nbsp;| 
<a href="pubs/icslp2008-dysana.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss08messlsp">52</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss, M.&nbsp;I. Mandel, and D.&nbsp;P.&nbsp;W. Ellis.
 <b>Source Separation Based on Binaural Cues and Source Model
  Constraints</b>.
 In <em>Proc. Interspeech</em>, pages 419--422, Brisbane, Australia,
  September 2008.
[&nbsp;<a href="ronwpubs_bib.html#weiss08messlsp">bib</a>&nbsp;| 
<a href="http://www.isca-speech.org/archive/interspeech_2008/i08_0419.html">http</a>&nbsp;| 
<a href="pubs/icslp2008-messl_sp-poster.pdf">poster</a>&nbsp;| 
<a href="pubs/icslp2008-messl_sp.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss07adapted_models">53</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss and D.&nbsp;P.&nbsp;W. Ellis.
 <b>Monaural Speech Separation Using Source-Adapted Models</b>.
 In <em>Proc. IEEE Workshop on Applications of Signal Processing to
  Audio and Acoustics (WASPAA)</em>, pages 114--117, New Paltz, USA, October
  2007.
[&nbsp;<a href="ronwpubs_bib.html#weiss07adapted_models">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ASPAA.2007.4393039">DOI</a>&nbsp;| 
<a href="SSC.html">web</a>&nbsp;| 
<a href="pubs/waspaa2007-adapted_models-slides.pdf">slides</a>&nbsp;| 
<a href="pubs/waspaa2007-adapted_models.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss06rvmsep">54</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss and D.&nbsp;P.&nbsp;W. Ellis.
 <b>Estimating Single-Channel Source Separation Masks: Relevance
  Vector Machine Classifiers vs. Pitch-Based Masking</b>.
 In <em>Proc. ISCA Tutorial and Research Workshop on Statistical
  Perceptual Audition (SAPA)</em>, pages 31--36, Pittsburgh, USA, September 2006.
[&nbsp;<a href="ronwpubs_bib.html#weiss06rvmsep">bib</a>&nbsp;| 
<a href="http://www.isca-speech.org/archive/sapa_2006/sap6_031.html">http</a>&nbsp;| 
<a href="pubs/sapa2006-rvmpvsourcesep-slides.pdf">slides</a>&nbsp;| 
<a href="pubs/sapa2006-rvmpvsourcesep.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="ellis06pvocvq">55</a>]
</td>
<td class="bibtexitem">
D.&nbsp;P.&nbsp;W. Ellis and R.&nbsp;J. Weiss.
 <b>Model-Based Monaural Source Separation Using a Vector-Quantized
  Phase-Vocoder Representation</b>.
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, pages V--957--960, Toulouse, France, May
  2006.
[&nbsp;<a href="ronwpubs_bib.html#ellis06pvocvq">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2006.1661436">DOI</a>&nbsp;| 
<a href="pubs/icassp2006-pvocvq.pdf">.pdf</a>&nbsp;]

</td>
</tr>
</table>
</div></p>



<h3>Teaching</h3>

<p><a name="teaching" id="teaching"></a>
I have taught/been a teaching assistant for:</p>

<ul>
<li>Spring 2010: <a href="http://www.ee.columbia.edu/~ronw/adst-spring2010">E85.2607</a> Advanced Digital Signal Theory (NYU)</li>
<li>Spring 2007: <a href="http://labrosa.ee.columbia.edu/e4896/wiki.pl">ELEN E4896/E4998</a> Music Signal Processing</li>
<li>Spring 2005: <a href="http://www.ee.columbia.edu/~eleft/e4896-Spring05/">ELEN E4896</a> Music Signal Processing</li>
<li>Fall 2004: <a href="http://www.ee.columbia.edu/~anastas/gist2004/">GIST E4060/E3060</a> Introduction to Genomic Information
Science and Technology</li>
<li>Fall 2003: <a href="http://www.cs.columbia.edu/~nieh/teaching/w4118_f03/">COMS W4118</a> Operating Systems I</li>
</ul>


<!-- Page published by Muse ends here -->
</div>
<hr>
<span class="footdate">
Last updated on February 13, 2020.
</span>

</body>
</html>
