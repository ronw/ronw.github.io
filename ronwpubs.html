
<!-- This document was automatically generated with bibtex2html 1.99
     (see http://www.lri.fr/~filliatr/bibtex2html/),
     with the following command:
     bibtex2html -q -d -r -noabstract -nodoc -nofooter -s ronw_web -nf slides slides -nf poster poster -nf web web -nf http http -nf arxiv arxiv -nf reviews reviews pubs/ronwpubs.bib  -->


<table>

<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss2021wavetacotron">1</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss, R.&nbsp;J. Skerry-Ryan, E.&nbsp;Battenberg, S.&nbsp;Mariooryad, and D.&nbsp;P.
  Kingma.<br>
 <b>Wave-Tacotron: Spectrogram-free end-to-end text-to-speech
  synthesis</b>.<br>
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, June 2021.<br>
[&nbsp;<a href="ronwpubs_bib.html#weiss2021wavetacotron">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP39728.2021.9413851">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/2011.03568">arxiv</a>&nbsp;| 
<a href="https://google.github.io/tacotron/publications/wave-tacotron/">web</a>&nbsp;| 
<a href="pubs/icassp2021-wavetaco-poster.pdf">poster</a>&nbsp;| 
<a href="pubs/icassp2021-wavetaco-slides.pdf">slides</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="elias2021parallel">2</a>]
</td>
<td class="bibtexitem">
I.&nbsp;Elias, H.&nbsp;Zen, J.&nbsp;Shen, Y.&nbsp;Zhang, Y.&nbsp;Jia, R.&nbsp;J. Weiss, and
  Y.&nbsp;Wu.<br>
 <b>Parallel Tacotron: Non-Autoregressive and Controllable
  TTS</b>.<br>
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, June 2021.<br>
[&nbsp;<a href="ronwpubs_bib.html#elias2021parallel">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP39728.2021.9414718">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/2010.11439">arxiv</a>&nbsp;| 
<a href="https://google.github.io/tacotron/publications/parallel_tacotron/">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="chen2021wavegrad">3</a>]
</td>
<td class="bibtexitem">
N.&nbsp;Chen, Y.&nbsp;Zhang, H.&nbsp;Zen, R.&nbsp;J. Weiss, M.&nbsp;Norouzi, and W.&nbsp;Chan.<br>
 <b>WaveGrad: Estimating Gradients for Waveform
  Generation</b>.<br>
 In <em>Proc. International Conference on Learning Representations
  (ICLR)</em>, May 2021.<br>
[&nbsp;<a href="ronwpubs_bib.html#chen2021wavegrad">bib</a>&nbsp;| 
<a href="https://openreview.net/forum?id=NsMLjcFaO8O">reviews</a>&nbsp;| 
<a href="https://arxiv.org/abs/2009.00713">arxiv</a>&nbsp;| 
<a href="https://wavegrad.github.io/">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="wisdom2020mixit">4</a>]
</td>
<td class="bibtexitem">
S.&nbsp;Wisdom, E.&nbsp;Tzinis, H.&nbsp;Erdogan, R.&nbsp;J. Weiss, K.&nbsp;Wilson, and J.&nbsp;R.
  Hershey.<br>
 <b>Unsupervised Sound Separation Using Mixture Invariant
  Training</b>.<br>
 In <em>Advances in Neural Information Processing Systems (NeurIPS)</em>,
  December 2020.<br>
[&nbsp;<a href="ronwpubs_bib.html#wisdom2020mixit">bib</a>&nbsp;| 
<a href="https://papers.nips.cc/paper/2020/hash/28538c394c36e4d5ea8ff5ad60562a93-Abstract.html">reviews</a>&nbsp;| 
<a href="https://arxiv.org/abs/2006.12701">arxiv</a>&nbsp;| 
<a href="https://universal-sound-separation.github.io/unsupervised_sound_separation/">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="wisdom2020speech_mixit">5</a>]
</td>
<td class="bibtexitem">
S.&nbsp;Wisdom, E.&nbsp;Tzinis, H.&nbsp;Erdogan, R.&nbsp;J. Weiss, K.&nbsp;Wilson, and J.&nbsp;R.
  Hershey.<br>
 <b>Unsupervised Speech Separation Using Mixtures of
  Mixtures</b>.<br>
 In <em>ICML 2020 Workshop on Self-supervision in Audio and Speech</em>,
  July 2020.<br>
[&nbsp;<a href="ronwpubs_bib.html#wisdom2020speech_mixit">bib</a>&nbsp;| 
<a href="https://openreview.net/forum?id=qMMzJGRPT2d">reviews</a>&nbsp;| 
<a href="https://universal-sound-separation.github.io/unsupervised_speech_separation/">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="sun2020prosody_prior">6</a>]
</td>
<td class="bibtexitem">
G.&nbsp;Sun, Y.&nbsp;Zhang, R.&nbsp;J. Weiss, Y.&nbsp;Cao, H.&nbsp;Zen, A.&nbsp;Rosenberg, B.&nbsp;Ramabhadran,
  and Y.&nbsp;Wu.<br>
 <b>Generating diverse and natural text-to-speech samples using a
  quantized fine-grained VAE and auto-regressive prosody prior</b>.<br>
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, pages 6699--6703, May 2020.<br>
[&nbsp;<a href="ronwpubs_bib.html#sun2020prosody_prior">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP40776.2020.9053436">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/2002.03788">arxiv</a>&nbsp;| 
<a href="https://google.github.io/tacotron/publications/prosody_prior">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="sun2020hierarchical_prosody">7</a>]
</td>
<td class="bibtexitem">
G.&nbsp;Sun, Y.&nbsp;Zhang, R.&nbsp;J. Weiss, Y.&nbsp;Cao, H.&nbsp;Zen, and Y.&nbsp;Wu.<br>
 <b>Fully-hierarchical fine-grained prosody modeling for
  interpretable speech synthesis</b>.<br>
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, pages 6264--6268, May 2020.<br>
[&nbsp;<a href="ronwpubs_bib.html#sun2020hierarchical_prosody">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP40776.2020.9053520">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/2002.03785">arxiv</a>&nbsp;| 
<a href="https://google.github.io/tacotron/publications/hierarchical_prosody">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="sainath2020joint">8</a>]
</td>
<td class="bibtexitem">
T.&nbsp;N. Sainath, R.&nbsp;Pang, R.&nbsp;J. Weiss, Y.&nbsp;He, C.-C. Chiu, and
  T.&nbsp;Strohman.<br>
 <b>An Attention-Based Joint Acoustic and Text on-Device End-To-End
  Model</b>.<br>
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, pages 7039--7043, May 2020.<br>
[&nbsp;<a href="ronwpubs_bib.html#sainath2020joint">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP40776.2020.9053510">DOI</a>&nbsp;| 
<a href="pubs/icassp2020-jatd.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="chorowski2019unsupervised">9</a>]
</td>
<td class="bibtexitem">
J.&nbsp;Chorowski, R.&nbsp;J. Weiss, S.&nbsp;Bengio, and A.&nbsp;van&nbsp;den Oord.<br>
 <b>Unsupervised speech representation learning using WaveNet
  autoencoders</b>.<br>
 <em>IEEE/ACM Transactions on Audio, Speech, and Language
  Processing</em>, 27(12):2041--2053, December 2019.<br>
[&nbsp;<a href="ronwpubs_bib.html#chorowski2019unsupervised">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TASLP.2019.2938863">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1901.08810">arxiv</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="zhang2019learning">10</a>]
</td>
<td class="bibtexitem">
Y.&nbsp;Zhang, R.&nbsp;J. Weiss, H.&nbsp;Zen, Y.&nbsp;Wu, Z.&nbsp;Chen, R.&nbsp;J. Skerry-Ryan, Y.&nbsp;Jia,
  A.&nbsp;Rosenberg, and B.&nbsp;Ramabhadran.<br>
 <b>Learning to Speak Fluently in a Foreign Language: Multilingual
  Speech Synthesis and Cross-Language Voice Cloning</b>.<br>
 In <em>Proc. Interspeech</em>, Graz, Austria, September
  2019.<br>
[&nbsp;<a href="ronwpubs_bib.html#zhang2019learning">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2019-2668">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1907.04448">arxiv</a>&nbsp;| 
<a href="https://google.github.io/tacotron/publications/multilingual">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="zen2019libritts">11</a>]
</td>
<td class="bibtexitem">
H.&nbsp;Zen, V.&nbsp;Dang, R.&nbsp;Clark, Y.&nbsp;Zhang, R.&nbsp;J. Weiss, Y.&nbsp;Jia, Z.&nbsp;Chen, and
  Y.&nbsp;Wu.<br>
 <b>LibriTTS: A Corpus Derived from LibriSpeech for
  Text-to-Speech</b>.<br>
 In <em>Proc. Interspeech</em>, Graz, Austria, September
  2019.<br>
[&nbsp;<a href="ronwpubs_bib.html#zen2019libritts">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2019-2441">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1904.02882">arxiv</a>&nbsp;| 
<a href="http://www.openslr.org/60/">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="biadsy2019parrotron">12</a>]
</td>
<td class="bibtexitem">
F.&nbsp;Biadsy, R.&nbsp;J. Weiss, P.&nbsp;J. Moreno, D.&nbsp;Kanvesky, and Y.&nbsp;Jia.<br>
 <b>Parrotron: An End-to-End Speech-to-Speech Conversion Model and
  its Applications to Hearing-Impaired Speech and Speech
  Separation</b>.<br>
 In <em>Proc. Interspeech</em>, Graz, Austria, September
  2019.<br>
[&nbsp;<a href="ronwpubs_bib.html#biadsy2019parrotron">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2019-1789">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1904.04169">arxiv</a>&nbsp;| 
<a href="https://google.github.io/tacotron/publications/parrotron">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="jia2019direct">13</a>]
</td>
<td class="bibtexitem">
Y.&nbsp;Jia, R.&nbsp;J. Weiss, F.&nbsp;Biadsy, W.&nbsp;Macherey, M.&nbsp;Johnson, Z.&nbsp;Chen, and
  Y.&nbsp;Wu.<br>
 <b>Direct Speech-to-Speech Translation with a Sequence-to-Sequence
  Model</b>.<br>
 In <em>Proc. Interspeech</em>, Graz, Austria, September
  2019.<br>
[&nbsp;<a href="ronwpubs_bib.html#jia2019direct">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2019-1951">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1904.06037">arxiv</a>&nbsp;| 
<a href="https://google-research.github.io/lingvo-lab/translatotron">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="wang2019voicefilter">14</a>]
</td>
<td class="bibtexitem">
Q.&nbsp;Wang, H.&nbsp;Muckenhirn, K.&nbsp;Wilson, P.&nbsp;Sridhar, Z.&nbsp;Wu, J.&nbsp;Hershey, R.&nbsp;A.
  Saurous, R.&nbsp;J. Weiss, Y.&nbsp;Jia, and I.&nbsp;Lopez-Moreno.<br>
 <b>VoiceFilter: Targeted Voice Separation by Speaker-Conditioned
  Spectrogram Masking</b>.<br>
 In <em>Proc. Interspeech</em>, Graz, Austria, September
  2019.<br>
[&nbsp;<a href="ronwpubs_bib.html#wang2019voicefilter">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2019-1101">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1810.04826">arxiv</a>&nbsp;| 
<a href="https://google.github.io/speaker-id/publications/VoiceFilter">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="antognini2019audio">15</a>]
</td>
<td class="bibtexitem">
J.&nbsp;M. Antognini, M.&nbsp;Hoffman, and R.&nbsp;J. Weiss.<br>
 <b>Audio Texture Synthesis with Random Neural Networks: Improving
  Diversity and Quality</b>.<br>
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, Brighton, UK, May 2019.<br>
[&nbsp;<a href="ronwpubs_bib.html#antognini2019audio">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2019.8682598">DOI</a>&nbsp;| 
<a href="https://antognini-google.github.io/audio_textures">web</a>&nbsp;| 
<a href="pubs/icassp2019-texture-poster.pdf">poster</a>&nbsp;| 
<a href="pubs/icassp2019-texture.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="guo2019spelling">16</a>]
</td>
<td class="bibtexitem">
J.&nbsp;Guo, T.&nbsp;N. Sainath, and R.&nbsp;J. Weiss.<br>
 <b>A Spelling Correction Model for End-to-End Speech
  Recognition</b>.<br>
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, Brighton, UK, May 2019.<br>
[&nbsp;<a href="ronwpubs_bib.html#guo2019spelling">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2019.8683745">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1902.07178">arxiv</a>&nbsp;| 
<a href="pubs/icassp2019-spelling-slides.pdf">slides</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="jia2019leveraging">17</a>]
</td>
<td class="bibtexitem">
Y.&nbsp;Jia, M.&nbsp;Johnson, W.&nbsp;Macherey, R.&nbsp;J. Weiss, Y.&nbsp;Cao, C.-C. Chiu, N.&nbsp;Ari,
  S.&nbsp;Laurenzo, and Y.&nbsp;Wu.<br>
 <b>Leveraging Weakly Supervised Data to Improve End-to-End
  Speech-to-Text Translation</b>.<br>
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, Brighton, UK, May 2019.<br>
[&nbsp;<a href="ronwpubs_bib.html#jia2019leveraging">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2019.8683343">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1811.02050">arxiv</a>&nbsp;| 
<a href="pubs/icassp2019-speech_translation-slides.pdf">slides</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="hsu2019hierarchical">18</a>]
</td>
<td class="bibtexitem">
W.&nbsp;N. Hsu, Y.&nbsp;Zhang, R.&nbsp;J. Weiss, H.&nbsp;Zen, Y.&nbsp;Wu, Y.&nbsp;Wang, Y.&nbsp;Cao, Y.&nbsp;Jia,
  Z.&nbsp;Chen, J.&nbsp;Shen, P.&nbsp;Nguyen, and R.&nbsp;Pang.<br>
 <b>Hierarchical Generative Modeling for Controllable Speech
  Synthesis</b>.<br>
 In <em>Proc. International Conference on Learning Representations
  (ICLR)</em>, New Orleans, USA, May 2019.<br>
[&nbsp;<a href="ronwpubs_bib.html#hsu2019hierarchical">bib</a>&nbsp;| 
<a href="https://openreview.net/forum?id=rygkk305YQ">reviews</a>&nbsp;| 
<a href="https://arxiv.org/abs/1810.07217">arxiv</a>&nbsp;| 
<a href="https://google.github.io/tacotron/publications/gmvae_controllable_tts">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="hsu2018disentangling">19</a>]
</td>
<td class="bibtexitem">
W.&nbsp;N. Hsu, Y.&nbsp;Zhang, R.&nbsp;J. Weiss, Y.&nbsp;A. Chung, Y.&nbsp;Wang, Y.&nbsp;Wu, and
  J.&nbsp;Glass.<br>
 <b>Disentangling Correlated Speaker and Noise for Speech Synthesis
  via Data Augmentation and Adversarial Factorization</b>.<br>
 In <em>NeurIPS 2018 Workshop on Interpretability and Robustness in
  Audio, Speech, and Language</em>, Montr&eacute;al, Canada, December
  2018.<br>
 also at <a href="https://dx.doi.org/10.1109/ICASSP.2019.8683561">ICASSP
  2019</a>.<br>
[&nbsp;<a href="ronwpubs_bib.html#hsu2018disentangling">bib</a>&nbsp;| 
<a href="https://openreview.net/forum?id=Bkg9ZeBB37">reviews</a>&nbsp;| 
<a href="https://google.github.io/tacotron/publications/adv_tts">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="jia2018multispeaker">20</a>]
</td>
<td class="bibtexitem">
Y.&nbsp;Jia, Y.&nbsp;Zhang, R.&nbsp;J. Weiss, Q.&nbsp;Wang, J.&nbsp;Shen, F.&nbsp;Ren, Z.&nbsp;Chen, P.&nbsp;Nguyen,
  R.&nbsp;Pang, I.&nbsp;Lopez-Moreno, and Y.&nbsp;Wu.<br>
 <b>Transfer Learning from Speaker Verification to Multispeaker
  Text-To-Speech Synthesis</b>.<br>
 In <em>Advances in Neural Information Processing Systems (NeurIPS)</em>,
  Montr&eacute;al, Canada, December 2018.<br>
[&nbsp;<a href="ronwpubs_bib.html#jia2018multispeaker">bib</a>&nbsp;| 
<a href="http://papers.nips.cc/paper/7700-transfer-learning-from-speaker-verification-to-multispeaker-text-to-speech-synthesis">reviews</a>&nbsp;| 
<a href="https://arxiv.org/abs/1806.04558">arxiv</a>&nbsp;| 
<a href="https://google.github.io/tacotron/publications/speaker_adaptation">web</a>&nbsp;| 
<a href="https://google.github.io/tacotron/publications/speaker_adaptation/poster.pdf">poster</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="skerryryan2018prosody">21</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Skerry-Ryan, E.&nbsp;Battenberg, Y.&nbsp;Xiao, Y.&nbsp;Wang, D.&nbsp;Stanton, J.&nbsp;Shor, R.&nbsp;J.
  Weiss, R.&nbsp;Clark, and R.&nbsp;A. Saurous.<br>
 <b>Towards End-to-End Prosody Transfer for Expressive Speech
  Synthesis with Tacotron</b>.<br>
 In <em>Proc. International Conference on Machine Learning (ICML)</em>,
  Stockholm, Sweden, July 2018.<br>
[&nbsp;<a href="ronwpubs_bib.html#skerryryan2018prosody">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1803.09047">arxiv</a>&nbsp;| 
<a href="https://research.googleblog.com/2018/03/expressive-speech-synthesis-with.html">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="antognini18textures">22</a>]
</td>
<td class="bibtexitem">
J.&nbsp;Antognini, M.&nbsp;Hoffman, and R.&nbsp;J. Weiss.<br>
 <b>Synthesizing Diverse, High-Quality Audio Textures</b>.<br>
 <em>arXiv preprint arXiv:1806.08002</em>, June 2018.<br>
[&nbsp;<a href="ronwpubs_bib.html#antognini18textures">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1806.08002">arxiv</a>&nbsp;| 
<a href="https://antognini-google.github.io/audio_textures/">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="chiu2018sota">23</a>]
</td>
<td class="bibtexitem">
C.-C. Chiu, T.&nbsp;N. Sainath, Y.&nbsp;Wu, R.&nbsp;Prabhavalkar, P.&nbsp;Nguyen, Z.&nbsp;Chen,
  A.&nbsp;Kannan, R.&nbsp;J. Weiss, K.&nbsp;Rao, K.&nbsp;Gonina, N.&nbsp;Jaitly, B.&nbsp;Li, J.&nbsp;Chorowski,
  and M.&nbsp;Bacchiani.<br>
 <b>State-of-the-art Speech Recognition With Sequence-to-Sequence
  Models</b>.<br>
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, Calgary, Canada, April 2018.<br>
[&nbsp;<a href="ronwpubs_bib.html#chiu2018sota">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1712.01769">arxiv</a>&nbsp;| 
<a href="https://research.googleblog.com/2017/12/improving-end-to-end-models-for-speech.html">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="toshniwal2018multilingual">24</a>]
</td>
<td class="bibtexitem">
S.&nbsp;Toshniwal, T.&nbsp;N. Sainath, R.&nbsp;J. Weiss, B.&nbsp;Li, P.&nbsp;Moreno, E.&nbsp;Weinstein, and
  K.&nbsp;Rao.<br>
 <b>Multilingual Speech Recognition With A Single End-To-End
  Model</b>.<br>
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, Calgary, Canada, April 2018.<br>
[&nbsp;<a href="ronwpubs_bib.html#toshniwal2018multilingual">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1711.01694">arxiv</a>&nbsp;| 
<a href="https://research.googleblog.com/2017/12/improving-end-to-end-models-for-speech.html">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="chorowski2018styletransfer">25</a>]
</td>
<td class="bibtexitem">
J.&nbsp;Chorowski, R.&nbsp;J. Weiss, R.&nbsp;A. Saurous, and S.&nbsp;Bengio.<br>
 <b>On Using Backpropagation for Speech Texture Generation and Voice
  Conversion</b>.<br>
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, Calgary, Canada, April 2018.<br>
[&nbsp;<a href="ronwpubs_bib.html#chorowski2018styletransfer">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1712.08363">arxiv</a>&nbsp;| 
<a href="https://google.github.io/speech_style_transfer/samples.html">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="shen2018tacotron2">26</a>]
</td>
<td class="bibtexitem">
J.&nbsp;Shen, R.&nbsp;Pang, R.&nbsp;J. Weiss, M.&nbsp;Schuster, N.&nbsp;Jaitly, Z.&nbsp;Yang, Z.&nbsp;Chen,
  Y.&nbsp;Zhang, Y.&nbsp;Wang, R.&nbsp;J. Skerry-Ryan, R.&nbsp;A. Saurous, Y.&nbsp;Agiomyrgiannakis, and
  Y.&nbsp;Wu.<br>
 <b>Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram
  Predictions</b>.<br>
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, Calgary, Canada, April 2018.<br>
[&nbsp;<a href="ronwpubs_bib.html#shen2018tacotron2">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1712.05884">arxiv</a>&nbsp;| 
<a href="https://research.googleblog.com/2017/12/tacotron-2-generating-human-like-speech.html">web</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="bello18content">27</a>]
</td>
<td class="bibtexitem">
J.&nbsp;P. Bello, P.&nbsp;Grosche, M.&nbsp;M&uuml;ller, and R.&nbsp;Weiss.<br>
 <b>Content-Based Methods for Knowledge Discovery in
  Music</b>.<br>
 In <em>Springer Handbook of Systematic Musicology</em>, pages 823--840.
  Springer, March 2018.<br>
[&nbsp;<a href="ronwpubs_bib.html#bello18content">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-662-55004-5_39">DOI</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="li2017acoustic">28</a>]
</td>
<td class="bibtexitem">
B.&nbsp;Li, T.&nbsp;N. Sainath, A.&nbsp;Narayanan, J.&nbsp;Caroselli, M.&nbsp;Bacchiani, A.&nbsp;Misra,
  I.&nbsp;Shafran, H.&nbsp;Sak, G.&nbsp;Pundak, K.&nbsp;Chin, K.&nbsp;C. Sim, R.&nbsp;J. Weiss, K.&nbsp;Wilson,
  E.&nbsp;Variani, C.&nbsp;Kim, O.&nbsp;Siohan, M.&nbsp;Weintraub, E.&nbsp;McDermott, R.&nbsp;Rose, and
  M.&nbsp;Shannon.<br>
 <b>Acoustic Modeling for Google Home</b>.<br>
 In <em>Proc. Interspeech</em>, Stockholm, Sweden, August
  2017.<br>
[&nbsp;<a href="ronwpubs_bib.html#li2017acoustic">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2017-234">DOI</a>&nbsp;| 
<a href="pubs/interspeech2017-googlehome.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss2017sequence">29</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss, J.&nbsp;Chorowski, N.&nbsp;Jaitly, Y.&nbsp;Wu, and Z.&nbsp;Chen.<br>
 <b>Sequence-to-Sequence Models Can Directly Translate Foreign
  Speech</b>.<br>
 In <em>Proc. Interspeech</em>, Stockholm, Sweden, August
  2017.<br>
[&nbsp;<a href="ronwpubs_bib.html#weiss2017sequence">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2017-503">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1703.08581">arxiv</a>&nbsp;| 
<a href="pubs/interspeech2017-speech_translation-slides.pdf">slides</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="wang2017tacotron">30</a>]
</td>
<td class="bibtexitem">
Y.&nbsp;Wang, R.&nbsp;J. Skerry-Ryan, D.&nbsp;Stanton, Y.&nbsp;Wu, R.&nbsp;J. Weiss, N.&nbsp;Jaitly, Z.&nbsp;Yang,
  Y.&nbsp;Xiao, Z.&nbsp;Chen, S.&nbsp;Bengio, Q.&nbsp;Le, Y.&nbsp;Agiomyrgiannakis, R.&nbsp;Clark, and R.&nbsp;A.
  Saurous.<br>
 <b>Tacotron: Towards End-To-End Speech Synthesis</b>.<br>
 In <em>Proc. Interspeech</em>, Stockholm, Sweden, August
  2017.<br>
[&nbsp;<a href="ronwpubs_bib.html#wang2017tacotron">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2017-1452">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1703.10135">arxiv</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="raffel2017online">31</a>]
</td>
<td class="bibtexitem">
C.&nbsp;Raffel, T.&nbsp;Luong, P.&nbsp;J. Liu, R.&nbsp;J. Weiss, and D.&nbsp;Eck.<br>
 <b>Online and Linear-Time Attention by Enforcing Monotonic
  Alignments</b>.<br>
 In <em>Proc. International Conference on Machine Learning (ICML)</em>,
  Sydney, Australia, August 2017.<br>
[&nbsp;<a href="ronwpubs_bib.html#raffel2017online">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1704.00784">arxiv</a>&nbsp;| 
<a href="http://proceedings.mlr.press/v70/raffel17a.html">http</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="hershey17audiocnn">32</a>]
</td>
<td class="bibtexitem">
S.&nbsp;Hershey, S.&nbsp;Chaudhuri, D.&nbsp;P.&nbsp;W. Ellis, J.&nbsp;F. Gemmeke, A.&nbsp;Jansen, R.&nbsp;C.
  Moore, M.&nbsp;Plakal, D.&nbsp;Platt, R.&nbsp;A. Saurous, B.&nbsp;Seybold, M.&nbsp;Slaney, R.&nbsp;J.
  Weiss, and K.&nbsp;Wilson.<br>
 <b>CNN Architectures for Large-Scale Audio
  Classification</b>.<br>
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, New Orleans, USA, March 2017.<br>
[&nbsp;<a href="ronwpubs_bib.html#hershey17audiocnn">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2017.7952132">DOI</a>&nbsp;| 
<a href="https://arxiv.org/abs/1609.09430">arxiv</a>&nbsp;| 
<a href="pubs/icassp2017-audiocnn.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="sainath17multichannel">33</a>]
</td>
<td class="bibtexitem">
T.&nbsp;N. Sainath, R.&nbsp;J. Weiss, K.&nbsp;W. Wilson, B.&nbsp;Li, A.&nbsp;Narayanan, E.&nbsp;Variani,
  M.&nbsp;Bacchiani, I.&nbsp;Shafran, A.&nbsp;Senior, K.&nbsp;W. Chin, A.&nbsp;Misra, and
  C.&nbsp;Kim.<br>
 <b>Multichannel Signal Processing with Deep Neural Networks for
  Automatic Speech Recognition</b>.<br>
 <em>IEEE/ACM Transactions on Audio, Speech, and Language
  Processing</em>, 25(5):965--979, February 2017.<br>
[&nbsp;<a href="ronwpubs_bib.html#sainath17multichannel">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TASLP.2017.2672401">DOI</a>&nbsp;| 
<a href="pubs/taslp2017-multichannel.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="sainath17raw">34</a>]
</td>
<td class="bibtexitem">
T.&nbsp;N. Sainath, R.&nbsp;J. Weiss, K.&nbsp;W. Wilson, B.&nbsp;Li, A.&nbsp;Narayanan, E.&nbsp;Variani,
  M.&nbsp;Bacchiani, I.&nbsp;Shafran, A.&nbsp;Senior, K.&nbsp;W. Chin, A.&nbsp;Misra, and
  C.&nbsp;Kim.<br>
 <b>Raw Multichannel Processing Using Deep Neural
  Networks</b>.<br>
 In <em>New Era for Robust Speech Recognition: Exploiting Deep
  Learning</em>. Springer, 2017.<br>
[&nbsp;<a href="ronwpubs_bib.html#sainath17raw">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1007/978-3-319-64680-0">DOI</a>&nbsp;| 
<a href="pubs/jsalt2017-raw.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="sainath16speedups">35</a>]
</td>
<td class="bibtexitem">
T.&nbsp;N. Sainath, A.&nbsp;Narayanan, R.&nbsp;J. Weiss, E.&nbsp;Variani, K.&nbsp;W. Wilson,
  M.&nbsp;Bacchiani, and I.&nbsp;Shafran.<br>
 <b>Reducing the Computational Complexity of Multimicrophone
  Acoustic Models with Integrated Feature Extraction</b>.<br>
 In <em>Proc. Interspeech</em>, San Francisco, USA, September
  2016.<br>
[&nbsp;<a href="ronwpubs_bib.html#sainath16speedups">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2016-92">DOI</a>&nbsp;| 
<a href="pubs/interspeech2016-waveform_cldnn_speedups.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="li16adaptive">36</a>]
</td>
<td class="bibtexitem">
B.&nbsp;Li, T.&nbsp;N. Sainath, R.&nbsp;J. Weiss, K.&nbsp;W. Wilson, and M.&nbsp;Bacchiani.<br>
 <b>Neural Network Adaptive Beamforming for Robust Multichannel
  Speech Recognition</b>.<br>
 In <em>Proc. Interspeech</em>, San Francisco, USA, September
  2016.<br>
[&nbsp;<a href="ronwpubs_bib.html#li16adaptive">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.21437/Interspeech.2016-173">DOI</a>&nbsp;| 
<a href="pubs/interspeech2016-waveform_cldnn_adaptive.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="sainath16factored">37</a>]
</td>
<td class="bibtexitem">
T.&nbsp;N. Sainath, R.&nbsp;J. Weiss, K.&nbsp;W. Wilson, A.&nbsp;Narayanan, and
  M.&nbsp;Bacchiani.<br>
 <b>Factored Spatial and Spectral Multichannel Raw Waveform
  CLDNNs</b>.<br>
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, Shanghai, China, March 2016.<br>
[&nbsp;<a href="ronwpubs_bib.html#sainath16factored">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2017.7952132">DOI</a>&nbsp;| 
<a href="pubs/icassp2016-factored_cldnn.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="sainath15multichannel">38</a>]
</td>
<td class="bibtexitem">
T.&nbsp;N. Sainath, R.&nbsp;J. Weiss, K.&nbsp;W. Wilson, A.&nbsp;Narayanan, M.&nbsp;Bacchiani, and
  A.&nbsp;Senior.<br>
 <b>Speaker Location and Microphone Spacing Invariant Acoustic
  Modeling from Raw Multichannel Waveforms</b>.<br>
 In <em>Proc. IEEE Automatic Speech Recognition and Understanding
  Workshop (ASRU)</em>, Scottsdale, USA, December 2015.<br>
[&nbsp;<a href="ronwpubs_bib.html#sainath15multichannel">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ASRU.2015.7404770">DOI</a>&nbsp;| 
<a href="pubs/asru2015-multichannel_cldnn.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="sainath15waveform_cldnn">39</a>]
</td>
<td class="bibtexitem">
T.&nbsp;N. Sainath, R.&nbsp;J. Weiss, A.&nbsp;Senior, K.&nbsp;W. Wilson, and
  O.&nbsp;Vinyals.<br>
 <b>Learning the Speech Front-End with Raw Waveform
  CLDNNs</b>.<br>
 In <em>Proc. Interspeech</em>, Dresden, Germany, September
  2015.<br>
[&nbsp;<a href="ronwpubs_bib.html#sainath15waveform_cldnn">bib</a>&nbsp;| 
<a href="pubs/interspeech2015-waveform_cldnn.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="hoshen15waveformam">40</a>]
</td>
<td class="bibtexitem">
Y.&nbsp;Hoshen, R.&nbsp;J. Weiss, and K.&nbsp;W. Wilson.<br>
 <b>Speech Acoustic Modeling from Raw Multichannel
  Waveforms</b>.<br>
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, Brisbane, Australia, April
  2015.<br>
[&nbsp;<a href="ronwpubs_bib.html#hoshen15waveformam">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2015.7178847">DOI</a>&nbsp;| 
<a href="pubs/icassp2015-waveformam.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weston14awe">41</a>]
</td>
<td class="bibtexitem">
J.&nbsp;Weston, R.&nbsp;Weiss, and H.&nbsp;Yee.<br>
 <b>Affinity Weighted Embedding</b>.<br>
 In <em>Proc. International Conference on Machine Learning (ICML)</em>,
  pages 1215--1223, Beijing, China, June 2014.<br>
[&nbsp;<a href="ronwpubs_bib.html#weston14awe">bib</a>&nbsp;| 
<a href="http://jmlr.org/proceedings/papers/v32/weston14.html">http</a>&nbsp;| 
<a href="pubs/icml2014-awe.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weston13kaos">42</a>]
</td>
<td class="bibtexitem">
J.&nbsp;Weston, H.&nbsp;Yee, and R.&nbsp;J. Weiss.<br>
 <b>Learning to Rank Recommendations with the k-order Statistic
  Loss</b>.<br>
 In <em>Proc. ACM Conference on Recommender Systems (RecSys)</em>,
  pages 245--248, Hong Kong, October 2013.<br>
[&nbsp;<a href="ronwpubs_bib.html#weston13kaos">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/2507157.2507210">DOI</a>&nbsp;| 
<a href="pubs/recsys2013-kaos.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weston13usermax">43</a>]
</td>
<td class="bibtexitem">
J.&nbsp;Weston, R.&nbsp;J. Weiss, and H.&nbsp;Yee.<br>
 <b>Nonlinear Latent Factorization by Embedding Multiple User
  Interests</b>.<br>
 In <em>Proc. ACM Conference on Recommender Systems (RecSys)</em>,
  pages 65--68, Hong Kong, October 2013.<br>
[&nbsp;<a href="ronwpubs_bib.html#weston13usermax">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1145/2507157.2507209">DOI</a>&nbsp;| 
<a href="pubs/recsys2013-usermax.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weston13awe">44</a>]
</td>
<td class="bibtexitem">
J.&nbsp;Weston, R.&nbsp;Weiss, and H.&nbsp;Yee.<br>
 <b>Affinity Weighted Embedding</b>.<br>
 In <em>Proc. International Conference on Learning Representations
  (ICLR)</em>, Scottsdale, USA, May 2013.<br>
[&nbsp;<a href="ronwpubs_bib.html#weston13awe">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1301.4171">arxiv</a>&nbsp;| 
<a href="http://openreview.net/document/8bc82d3f-df5e-4602-bc3d-2f6fa0196f5f">http</a>&nbsp;| 
<a href="pubs/iclr2013-awe.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weston12lcr">45</a>]
</td>
<td class="bibtexitem">
J.&nbsp;Weston, C.&nbsp;Wang, R.&nbsp;Weiss, and A.&nbsp;Berenzweig.<br>
 <b>Latent Collaborative Retrieval</b>.<br>
 In <em>Proc. International Conference on Machine Learning (ICML)</em>,
  Edinburgh, Scotland, June 2012.<br>
[&nbsp;<a href="ronwpubs_bib.html#weston12lcr">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1206.4603">arxiv</a>&nbsp;| 
<a href="http://icml.cc/discuss/2012/12.html">http</a>&nbsp;| 
<a href="pubs/icml2012-lcr.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="pedregosa11scikit-learn">46</a>]
</td>
<td class="bibtexitem">
F.&nbsp;Pedregosa, G.&nbsp;Varoquaux, A.&nbsp;Gramfort, V.&nbsp;Michel, B.&nbsp;Thirion, O.&nbsp;Grisel,
  M.&nbsp;Blondel, P.&nbsp;Prettenhofer, R.&nbsp;Weiss, V.&nbsp;Dubourg, J.&nbsp;Vanderplas, A.&nbsp;Passos,
  D.&nbsp;Cournapeau, M.&nbsp;Brucher, M.&nbsp;Perrot, and &Eacute;. Duchesnay.<br>
 <b>scikit-learn: Machine Learning in Python</b>.<br>
 <em>Journal of Machine Learning Research</em>, 12:2825--2830, October
  2011.<br>
[&nbsp;<a href="ronwpubs_bib.html#pedregosa11scikit-learn">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1201.0490">arxiv</a>&nbsp;| 
<a href="http://jmlr.org/papers/v12/pedregosa11a.html">http</a>&nbsp;| 
<a href="pubs/jmlr2011-scikit-learn.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss11siplca">47</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss and J.&nbsp;P. Bello.<br>
 <b>Unsupervised Discovery of Temporal Structure in
  Music</b>.<br>
 <em>IEEE Journal of Selected Topics in Signal Processing</em>,
  5(6):1240--1251, October 2011.<br>
[&nbsp;<a href="ronwpubs_bib.html#weiss11siplca">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/JSTSP.2011.2145356">DOI</a>&nbsp;| 
<a href="pubs/jstsp2011-siplca.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="bertin11evaluating">48</a>]
</td>
<td class="bibtexitem">
T.&nbsp;Bertin-Mahieux, G.&nbsp;Grindlay, R.&nbsp;J. Weiss, and D.&nbsp;P.&nbsp;W. Ellis.<br>
 <b>Evaluating Music Sequence Models Through Missing
  Data</b>.<br>
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, pages 177--180, Prague, Czech Republic,
  May 2011.<br>
[&nbsp;<a href="ronwpubs_bib.html#bertin11evaluating">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2011.5946369">DOI</a>&nbsp;| 
<a href="pubs/icassp2011-imputation.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss11messlev">49</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss, M.&nbsp;I. Mandel, and D.&nbsp;P.&nbsp;W. Ellis.<br>
 <b>Combining Localization Cues and Source Model Constraints for
  Binaural Source Separation</b>.<br>
 <em>Speech Communication</em>, 53(5):606--621, May 2011.<br>
 Special issue on Perceptual and Statistical Audition.<br>
[&nbsp;<a href="ronwpubs_bib.html#weiss11messlev">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.specom.2011.01.003">DOI</a>&nbsp;| 
<a href="pubs/specom2011-messlev.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="bertin10patterns">50</a>]
</td>
<td class="bibtexitem">
T.&nbsp;Bertin-Mahieux, R.&nbsp;J. Weiss, and D.&nbsp;P.&nbsp;W. Ellis.<br>
 <b>Clustering Beat-Chroma Patterns in a Large Music
  Database</b>.<br>
 In <em>Proc. International Society for Music Information Retrieval
  Conference (ISMIR)</em>, pages 111--116, Utrecht, Netherlands, August
  2010.<br>
[&nbsp;<a href="ronwpubs_bib.html#bertin10patterns">bib</a>&nbsp;| 
<a href="http://www.columbia.edu/~tb2332/ProjClustering/ClusteringChromas.html">web</a>&nbsp;| 
<a href="pubs/ismir2010-beatchromapatterns.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss10nmfseg">51</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss and J.&nbsp;P. Bello.<br>
 <b>Identifying Repeated Patterns in Music Using Sparse Convolutive
  Non-Negative Matrix Factorization</b>.<br>
 In <em>Proc. International Society for Music Information Retrieval
  Conference (ISMIR)</em>, pages 123--128, Utrecht, Netherlands, August
  2010.<br>
 Best Paper Award.<br>
[&nbsp;<a href="ronwpubs_bib.html#weiss10nmfseg">bib</a>&nbsp;| 
<a href="http://ronw.github.com/siplca-segmentation">web</a>&nbsp;| 
<a href="pubs/ismir2010-nmfseg-slides.pdf">slides</a>&nbsp;| 
<a href="pubs/ismir2010-nmfseg.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="cho10chordreco">52</a>]
</td>
<td class="bibtexitem">
T.&nbsp;Cho, R.&nbsp;J. Weiss, and J.&nbsp;P. Bello.<br>
 <b>Exploring Common Variations in State of the Art Chord
  Recognition Systems</b>.<br>
 In <em>Proc. Sound and Music Computing Conference (SMC)</em>, pages
  1--8, Barcelona, Spain, July 2010.<br>
[&nbsp;<a href="ronwpubs_bib.html#cho10chordreco">bib</a>&nbsp;| 
<a href="pubs/smc2010-chordreco.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="mandel10messl">53</a>]
</td>
<td class="bibtexitem">
M.&nbsp;I. Mandel, R.&nbsp;J. Weiss, and D.&nbsp;P.&nbsp;W. Ellis.<br>
 <b>Model-Based Expectation-Maximization Source Separation and
  Localization</b>.<br>
 <em>IEEE Transactions on Audio, Speech, and Language Processing</em>,
  18(2):382--394, February 2010.<br>
[&nbsp;<a href="ronwpubs_bib.html#mandel10messl">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/TASL.2009.2029711">DOI</a>&nbsp;| 
<a href="http://github.com/mim/messl">web</a>&nbsp;| 
<a href="pubs/taslp09-messl.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss10ssc">54</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss and D.&nbsp;P.&nbsp;W. Ellis.<br>
 <b>Speech Separation Using Speaker-Adapted Eigenvoice Speech
  Models</b>.<br>
 <em>Computer Speech and Language</em>, 24(1):16--29, January
  2010.<br>
 Speech Separation and Recognition Challenge.<br>
[&nbsp;<a href="ronwpubs_bib.html#weiss10ssc">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1016/j.csl.2008.03.003">DOI</a>&nbsp;| 
<a href="pubs/csl2008-eigenvoice_speech_sep.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss09vem">55</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss and D.&nbsp;P.&nbsp;W. Ellis.<br>
 <b>A Variational EM Algorithm for Learning Eigenvoice Parameters
  in Mixed Signals</b>.<br>
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, pages 113--116, Taipei, Taiwan, April
  2009.<br>
[&nbsp;<a href="ronwpubs_bib.html#weiss09vem">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2009.4959533">DOI</a>&nbsp;| 
<a href="pubs/icassp2009-ev_vem-poster.pdf">poster</a>&nbsp;| 
<a href="pubs/icassp2009-ev_vem.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss09thesis">56</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss.<br>
 <b>Underdetermined Source Separation Using Speaker Subspace
  Models</b>.<br>
 PhD thesis, Department of Electrical Engineering, Columbia
  University, 2009.<br>
[&nbsp;<a href="ronwpubs_bib.html#weiss09thesis">bib</a>&nbsp;| 
<a href="pubs/ronw-thesis-slides.pdf">slides</a>&nbsp;| 
<a href="pubs/ronw-thesis.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss08dysana">57</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss and T.&nbsp;Kristjansson.<br>
 <b>DySANA: Dynamic Speech and Noise Adaptation for Voice
  Activity Detection</b>.<br>
 In <em>Proc. Interspeech</em>, pages 127--130, Brisbane, Australia,
  September 2008.<br>
[&nbsp;<a href="ronwpubs_bib.html#weiss08dysana">bib</a>&nbsp;| 
<a href="http://www.isca-speech.org/archive/interspeech_2008/i08_0127.html">http</a>&nbsp;| 
<a href="pubs/icslp2008-dysana-poster.pdf">poster</a>&nbsp;| 
<a href="pubs/icslp2008-dysana.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss08messlsp">58</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss, M.&nbsp;I. Mandel, and D.&nbsp;P.&nbsp;W. Ellis.<br>
 <b>Source Separation Based on Binaural Cues and Source Model
  Constraints</b>.<br>
 In <em>Proc. Interspeech</em>, pages 419--422, Brisbane, Australia,
  September 2008.<br>
[&nbsp;<a href="ronwpubs_bib.html#weiss08messlsp">bib</a>&nbsp;| 
<a href="http://www.isca-speech.org/archive/interspeech_2008/i08_0419.html">http</a>&nbsp;| 
<a href="pubs/icslp2008-messl_sp-poster.pdf">poster</a>&nbsp;| 
<a href="pubs/icslp2008-messl_sp.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss07adapted_models">59</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss and D.&nbsp;P.&nbsp;W. Ellis.<br>
 <b>Monaural Speech Separation Using Source-Adapted
  Models</b>.<br>
 In <em>Proc. IEEE Workshop on Applications of Signal Processing to
  Audio and Acoustics (WASPAA)</em>, pages 114--117, New Paltz, USA, October
  2007.<br>
[&nbsp;<a href="ronwpubs_bib.html#weiss07adapted_models">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ASPAA.2007.4393039">DOI</a>&nbsp;| 
<a href="SSC.html">web</a>&nbsp;| 
<a href="pubs/waspaa2007-adapted_models-slides.pdf">slides</a>&nbsp;| 
<a href="pubs/waspaa2007-adapted_models.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="weiss06rvmsep">60</a>]
</td>
<td class="bibtexitem">
R.&nbsp;J. Weiss and D.&nbsp;P.&nbsp;W. Ellis.<br>
 <b>Estimating Single-Channel Source Separation Masks: Relevance
  Vector Machine Classifiers vs. Pitch-Based Masking</b>.<br>
 In <em>Proc. ISCA Tutorial and Research Workshop on Statistical
  Perceptual Audition (SAPA)</em>, pages 31--36, Pittsburgh, USA, September
  2006.<br>
[&nbsp;<a href="ronwpubs_bib.html#weiss06rvmsep">bib</a>&nbsp;| 
<a href="http://www.isca-speech.org/archive/sapa_2006/sap6_031.html">http</a>&nbsp;| 
<a href="pubs/sapa2006-rvmpvsourcesep-slides.pdf">slides</a>&nbsp;| 
<a href="pubs/sapa2006-rvmpvsourcesep.pdf">.pdf</a>&nbsp;]

</td>
</tr>


<tr valign="top">
<td align="right" class="bibtexnumber">
[<a name="ellis06pvocvq">61</a>]
</td>
<td class="bibtexitem">
D.&nbsp;P.&nbsp;W. Ellis and R.&nbsp;J. Weiss.<br>
 <b>Model-Based Monaural Source Separation Using a Vector-Quantized
  Phase-Vocoder Representation</b>.<br>
 In <em>Proc. IEEE International Conference on Acoustics, Speech,
  and Signal Processing (ICASSP)</em>, pages V--957--960, Toulouse, France, May
  2006.<br>
[&nbsp;<a href="ronwpubs_bib.html#ellis06pvocvq">bib</a>&nbsp;| 
<a href="http://dx.doi.org/10.1109/ICASSP.2006.1661436">DOI</a>&nbsp;| 
<a href="pubs/icassp2006-pvocvq.pdf">.pdf</a>&nbsp;]

</td>
</tr>
</table>